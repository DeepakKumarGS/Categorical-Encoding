{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Feature Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been provided with a dataset that only has categorical variables and we are asked to try out different encoding schemes and compare how they perform.The competition is binary classification challenge with only categorical variables to train on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/cdeotte/high-scoring-lgbm-malware-0-702-0-775\n",
    "#https://www.kaggle.com/fabiendaniel/detecting-malwares-with-lgbm\n",
    "#https://www.kaggle.com/humananalog/xgboost-lasso\n",
    "#https://www.kaggle.com/ogrellier/good-fun-with-ligthgbm\n",
    "#https://www.kaggle.com/mlisovyi/modular-good-fun-with-ligthgbm/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle=0\n",
    "\n",
    "if kaggle==0:\n",
    "    train=pd.read_csv(\"data/train.csv\")\n",
    "    test=pd.read_csv(\"data/test.csv\")\n",
    "    sample_submission=pd.read_csv(\"data/sample_submission.csv\")\n",
    "    \n",
    "else:\n",
    "    train=pd.read_csv(\"../input/train.csv\")\n",
    "    test=pd.read_csv(\"../input/test.csv\")\n",
    "    sample_submission=pd.read_csv(\"../input/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>2f4cb3d51</td>\n",
       "      <td>2</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>D</td>\n",
       "      <td>kr</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>f83c56c21</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>bF</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>ae6800dd0</td>\n",
       "      <td>1</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>h</td>\n",
       "      <td>R</td>\n",
       "      <td>Jc</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>8270f0d71</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>i</td>\n",
       "      <td>D</td>\n",
       "      <td>kW</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>b164b72a7</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>a</td>\n",
       "      <td>R</td>\n",
       "      <td>qP</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bin_0  bin_1  bin_2 bin_3 bin_4  nom_0      nom_1    nom_2    nom_3  \\\n",
       "0   0      0      0      0     T     Y  Green   Triangle    Snake  Finland   \n",
       "1   1      0      1      0     T     Y  Green  Trapezoid  Hamster   Russia   \n",
       "2   2      0      0      0     F     Y   Blue  Trapezoid     Lion   Russia   \n",
       "3   3      0      1      0     F     Y    Red  Trapezoid    Snake   Canada   \n",
       "4   4      0      0      0     F     N    Red  Trapezoid     Lion   Canada   \n",
       "\n",
       "   ...        nom_9 ord_0        ord_1        ord_2 ord_3 ord_4  ord_5 day  \\\n",
       "0  ...    2f4cb3d51     2  Grandmaster         Cold     h     D     kr   2   \n",
       "1  ...    f83c56c21     1  Grandmaster          Hot     a     A     bF   7   \n",
       "2  ...    ae6800dd0     1       Expert     Lava Hot     h     R     Jc   7   \n",
       "3  ...    8270f0d71     1  Grandmaster  Boiling Hot     i     D     kW   2   \n",
       "4  ...    b164b72a7     1  Grandmaster     Freezing     a     R     qP   7   \n",
       "\n",
       "  month target  \n",
       "0     2      0  \n",
       "1     8      0  \n",
       "2     2      0  \n",
       "3     1      1  \n",
       "4     8      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300000, 25), (200000, 24))"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the train dataset has 25 categorical columns with varying degree of cardinality.\n",
    "\n",
    "Let check the distribution of the target value to understand whether the dataset is balanced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    208236\n",
       "1     91764\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the target has lot of 0's than 1's.Its an unbalanced problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         int64\n",
       "bin_0      int64\n",
       "bin_1      int64\n",
       "bin_2      int64\n",
       "bin_3     object\n",
       "bin_4     object\n",
       "nom_0     object\n",
       "nom_1     object\n",
       "nom_2     object\n",
       "nom_3     object\n",
       "nom_4     object\n",
       "nom_5     object\n",
       "nom_6     object\n",
       "nom_7     object\n",
       "nom_8     object\n",
       "nom_9     object\n",
       "ord_0      int64\n",
       "ord_1     object\n",
       "ord_2     object\n",
       "ord_3     object\n",
       "ord_4     object\n",
       "ord_5     object\n",
       "day        int64\n",
       "month      int64\n",
       "target     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        int64\n",
       "bin_0     int64\n",
       "bin_1     int64\n",
       "bin_2     int64\n",
       "bin_3    object\n",
       "bin_4    object\n",
       "nom_0    object\n",
       "nom_1    object\n",
       "nom_2    object\n",
       "nom_3    object\n",
       "nom_4    object\n",
       "nom_5    object\n",
       "nom_6    object\n",
       "nom_7    object\n",
       "nom_8    object\n",
       "nom_9    object\n",
       "ord_0     int64\n",
       "ord_1    object\n",
       "ord_2    object\n",
       "ord_3    object\n",
       "ord_4    object\n",
       "ord_5    object\n",
       "day       int64\n",
       "month     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting bin_0 into category datatype\n",
      "\n",
      "Converting bin_1 into category datatype\n",
      "\n",
      "Converting bin_2 into category datatype\n",
      "\n",
      "Converting bin_3 into category datatype\n",
      "\n",
      "Converting bin_4 into category datatype\n",
      "\n",
      "Converting nom_0 into category datatype\n",
      "\n",
      "Converting nom_1 into category datatype\n",
      "\n",
      "Converting nom_2 into category datatype\n",
      "\n",
      "Converting nom_3 into category datatype\n",
      "\n",
      "Converting nom_4 into category datatype\n",
      "\n",
      "Converting nom_5 into category datatype\n",
      "\n",
      "Converting nom_6 into category datatype\n",
      "\n",
      "Converting nom_7 into category datatype\n",
      "\n",
      "Converting nom_8 into category datatype\n",
      "\n",
      "Converting nom_9 into category datatype\n",
      "\n",
      "Converting ord_0 into category datatype\n",
      "\n",
      "Converting ord_1 into category datatype\n",
      "\n",
      "Converting ord_2 into category datatype\n",
      "\n",
      "Converting ord_3 into category datatype\n",
      "\n",
      "Converting ord_4 into category datatype\n",
      "\n",
      "Converting ord_5 into category datatype\n",
      "\n",
      "Converting day into category datatype\n",
      "\n",
      "Converting month into category datatype\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#convert all the columns to category datatype:\n",
    "for f in train.columns:\n",
    "    if f==\"id\" or f==\"target\": continue\n",
    "    print(f'Converting {f} into category datatype\\n')\n",
    "    train[f]=train[f].astype('category')\n",
    "    test[f]=test[f].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cardinality of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For binary columns , the cardinality will be 2.Lets separate them out .\n",
    "binary_columns=[c for c in train.columns if train[c].nunique()==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4', 'target']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns=[c for c in train.columns if (c not in binary_columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinality=[]\n",
    "for c in categorical_columns:\n",
    "    if c=='id':continue\n",
    "    cardinality.append([c,train[c].nunique()])\n",
    "cardinality.sort(key=lambda x:x[1],reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['nom_9', 11981],\n",
       " ['nom_8', 2215],\n",
       " ['nom_7', 1220],\n",
       " ['nom_6', 522],\n",
       " ['nom_5', 222],\n",
       " ['ord_5', 192],\n",
       " ['ord_4', 26],\n",
       " ['ord_3', 15],\n",
       " ['month', 12],\n",
       " ['day', 7],\n",
       " ['nom_1', 6],\n",
       " ['nom_2', 6],\n",
       " ['nom_3', 6],\n",
       " ['ord_2', 6],\n",
       " ['ord_1', 5],\n",
       " ['nom_4', 4],\n",
       " ['nom_0', 3],\n",
       " ['ord_0', 3]]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardinality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are 7 columns with high cardinality.Feature encoding for these columns may include frequency encoding which is based on the ranking of categories based on the frequency of occurence in the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns that can be safely label encoded\n",
    "good_label_cols = [col for col in categorical_columns if \n",
    "                   set(train[col]) == set(test[col])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nom_0',\n",
       " 'nom_1',\n",
       " 'nom_2',\n",
       " 'nom_3',\n",
       " 'nom_4',\n",
       " 'nom_5',\n",
       " 'nom_6',\n",
       " 'ord_0',\n",
       " 'ord_1',\n",
       " 'ord_2',\n",
       " 'ord_3',\n",
       " 'ord_4',\n",
       " 'ord_5',\n",
       " 'day',\n",
       " 'month']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from https://www.kaggle.com/fabiendaniel/detecting-malwares-with-lgbm\n",
    "def frequency_encoding(variable):\n",
    "    t = pd.concat([train[variable], test[variable]]).value_counts().reset_index()\n",
    "    t = t.reset_index()\n",
    "    t.loc[t[variable] == 1, 'level_0'] = np.nan\n",
    "    t.set_index('index', inplace=True)\n",
    "    max_label = t['level_0'].max() + 1\n",
    "    t.fillna(max_label, inplace=True)\n",
    "    return t.to_dict()['level_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " #frequency_encoded_columns=['nom_9','nom_8','nom_7','nom_6','nom_5','ord_5','ord_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 55.29it/s]\n"
     ]
    }
   ],
   "source": [
    "for variable in tqdm(good_label_cols):\n",
    "    freq_encod_dict=frequency_encoding(variable)\n",
    "    train[variable+'_FE']=train[variable].map(lambda x:freq_encod_dict.get(x,np.nan))\n",
    "    test[variable+'_FE']=test[variable].map(lambda x:freq_encod_dict.get(x,np.nan))\n",
    "    categorical_columns.remove(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study\n",
    "\n",
    "def factorize(train, test, features, na_value=-9999, full=False, sort=True):\n",
    "    \"\"\"Factorize categorical features.\n",
    "    Parameters\n",
    "    ----------\n",
    "    train : pd.DataFrame\n",
    "    test : pd.DataFrame\n",
    "    features : list\n",
    "           Column names in the DataFrame to be encoded.\n",
    "    na_value : int, default -9999\n",
    "    full : bool, default False\n",
    "        Whether use all columns from train/test or only from train.\n",
    "    sort : bool, default True\n",
    "        Sort by values.\n",
    "    Returns\n",
    "    -------\n",
    "    train : pd.DataFrame\n",
    "    test : pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    for column in features:\n",
    "        if full:\n",
    "            vs = pd.concat([train[column], test[column]])\n",
    "            labels, indexer = pd.factorize(vs, sort=sort)\n",
    "        else:\n",
    "            labels, indexer = pd.factorize(train[column], sort=sort)\n",
    "\n",
    "        train[column+'_LE'] = indexer.get_indexer(train[column])\n",
    "        test[column+'_LE'] = indexer.get_indexer(test[column])\n",
    "\n",
    "        if na_value != -1:\n",
    "            train[column] = train[column].replace(-1, na_value)\n",
    "            test[column] = test[column].replace(-1, na_value)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexer = {}\n",
    "# for col in tqdm(categorical_columns):\n",
    "#     if col == 'id': continue\n",
    "#     _, indexer[col] = pd.factorize([train[col],test[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_columns.remove('id')\n",
    "train,test=factorize(train,test,categorical_columns,full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train,test=factorize(train,test,frequency_encoded_columns,full=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in tqdm(categorical_columns):\n",
    "#     if col=='id':continue\n",
    "#     train[col+'_LE']=indexer[col].get_indexer(train[col])\n",
    "#     test[col+'_LE']=indexer[col].get_indexer(test[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do one hot encoding for all the binary categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat_dum=pd.DataFrame()\n",
    "test_cat_dum=pd.DataFrame()\n",
    "for c_ in binary_columns:\n",
    "    if c_=='target':continue\n",
    "    train_cat_dum=pd.concat([train_cat_dum,pd.get_dummies(train[c_],prefix=c_).astype(np.uint8)],axis=1)\n",
    "    test_cat_dum=pd.concat([test_cat_dum,pd.get_dummies(test[c_],prefix=c_).astype(np.uint8)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_0_0</th>\n",
       "      <th>bin_0_1</th>\n",
       "      <th>bin_1_0</th>\n",
       "      <th>bin_1_1</th>\n",
       "      <th>bin_2_0</th>\n",
       "      <th>bin_2_1</th>\n",
       "      <th>bin_3_F</th>\n",
       "      <th>bin_3_T</th>\n",
       "      <th>bin_4_N</th>\n",
       "      <th>bin_4_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bin_0_0  bin_0_1  bin_1_0  bin_1_1  bin_2_0  bin_2_1  bin_3_F  bin_3_T  \\\n",
       "0        1        0        1        0        1        0        0        1   \n",
       "1        1        0        0        1        1        0        0        1   \n",
       "2        1        0        1        0        1        0        1        0   \n",
       "3        1        0        0        1        1        0        1        0   \n",
       "4        1        0        1        0        1        0        1        0   \n",
       "\n",
       "   bin_4_N  bin_4_Y  \n",
       "0        0        1  \n",
       "1        0        1  \n",
       "2        0        1  \n",
       "3        0        1  \n",
       "4        1        0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cat_dum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.concat([train,train_cat_dum],axis=1)\n",
    "test=pd.concat([test,test_cat_dum],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>...</th>\n",
       "      <th>bin_0_0</th>\n",
       "      <th>bin_0_1</th>\n",
       "      <th>bin_1_0</th>\n",
       "      <th>bin_1_1</th>\n",
       "      <th>bin_2_0</th>\n",
       "      <th>bin_2_1</th>\n",
       "      <th>bin_3_F</th>\n",
       "      <th>bin_3_T</th>\n",
       "      <th>bin_4_N</th>\n",
       "      <th>bin_4_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Finland</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Russia</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Canada</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id bin_0 bin_1 bin_2 bin_3 bin_4  nom_0      nom_1    nom_2    nom_3  \\\n",
       "0   0     0     0     0     T     Y  Green   Triangle    Snake  Finland   \n",
       "1   1     0     1     0     T     Y  Green  Trapezoid  Hamster   Russia   \n",
       "2   2     0     0     0     F     Y   Blue  Trapezoid     Lion   Russia   \n",
       "3   3     0     1     0     F     Y    Red  Trapezoid    Snake   Canada   \n",
       "4   4     0     0     0     F     N    Red  Trapezoid     Lion   Canada   \n",
       "\n",
       "    ...   bin_0_0 bin_0_1 bin_1_0 bin_1_1 bin_2_0 bin_2_1 bin_3_F bin_3_T  \\\n",
       "0   ...         1       0       1       0       1       0       0       1   \n",
       "1   ...         1       0       0       1       1       0       0       1   \n",
       "2   ...         1       0       1       0       1       0       1       0   \n",
       "3   ...         1       0       0       1       1       0       1       0   \n",
       "4   ...         1       0       1       0       1       0       1       0   \n",
       "\n",
       "  bin_4_N bin_4_Y  \n",
       "0       0       1  \n",
       "1       0       1  \n",
       "2       0       1  \n",
       "3       0       1  \n",
       "4       1       0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,we have taken care of all the categorical variables.Lets build the model and with 5 fold cross validation .Before this ,lets delete the original categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['nom_0_FE', 'nom_1_FE', 'nom_2_FE', 'nom_3_FE', 'nom_4_FE', 'nom_5_FE',\n",
       "        'nom_6_FE', 'ord_0_FE', 'ord_1_FE', 'ord_2_FE', 'ord_3_FE', 'ord_4_FE',\n",
       "        'ord_5_FE', 'day_FE', 'month_FE', 'nom_7_LE', 'nom_8_LE', 'nom_9_LE',\n",
       "        'bin_0_0', 'bin_0_1', 'bin_1_0', 'bin_1_1', 'bin_2_0', 'bin_2_1',\n",
       "        'bin_3_F', 'bin_3_T', 'bin_4_N', 'bin_4_Y'],\n",
       "       dtype='object'),\n",
       " Index(['nom_0_FE', 'nom_1_FE', 'nom_2_FE', 'nom_3_FE', 'nom_4_FE', 'nom_5_FE',\n",
       "        'nom_6_FE', 'ord_0_FE', 'ord_1_FE', 'ord_2_FE', 'ord_3_FE', 'ord_4_FE',\n",
       "        'ord_5_FE', 'day_FE', 'month_FE', 'nom_7_LE', 'nom_8_LE', 'nom_9_LE',\n",
       "        'bin_0_0', 'bin_0_1', 'bin_1_0', 'bin_1_1', 'bin_2_0', 'bin_2_1',\n",
       "        'bin_3_F', 'bin_3_T', 'bin_4_N', 'bin_4_Y'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns,test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_remove=['id', 'bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4', 'nom_0', 'nom_1',\n",
    "       'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9',\n",
    "       'ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5', 'day', 'month','id_LE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(cols_to_remove,axis=1)\n",
    "test=test.drop(cols_to_remove,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 29)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 28)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing required libraries:\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train['target']\n",
    "del train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds=StratifiedKFold(n_splits=5,shuffle=True,random_state=1234)\n",
    "feats=[f for f in train.columns if f not in ['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'nom_7', 'nom_8', 'nom_9']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds = np.zeros(train.shape[0])\n",
    "sub_preds = np.zeros(test.shape[0])\n",
    "    \n",
    "feature_importance_df = pd.DataFrame()\n",
    "categorical_features=[c for c in train.columns if c not in ['id_LE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nom_0_FE',\n",
       " 'nom_1_FE',\n",
       " 'nom_2_FE',\n",
       " 'nom_3_FE',\n",
       " 'nom_4_FE',\n",
       " 'nom_5_FE',\n",
       " 'nom_6_FE',\n",
       " 'ord_0_FE',\n",
       " 'ord_1_FE',\n",
       " 'ord_2_FE',\n",
       " 'ord_3_FE',\n",
       " 'ord_4_FE',\n",
       " 'ord_5_FE',\n",
       " 'day_FE',\n",
       " 'month_FE',\n",
       " 'nom_7_LE',\n",
       " 'nom_8_LE',\n",
       " 'nom_9_LE',\n",
       " 'bin_0_0',\n",
       " 'bin_0_1',\n",
       " 'bin_1_0',\n",
       " 'bin_1_1',\n",
       " 'bin_2_0',\n",
       " 'bin_2_1',\n",
       " 'bin_3_F',\n",
       " 'bin_3_T',\n",
       " 'bin_4_N',\n",
       " 'bin_4_Y']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_tr_index, bayesian_val_index  = list(StratifiedKFold(n_splits=3, shuffle=True, random_state=1).split(train.values, y.values))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(\n",
    "    num_leaves,  # int\n",
    "    min_data_in_leaf,  # int\n",
    "    learning_rate,\n",
    "    lambda_l1,\n",
    "    feature_fraction,\n",
    "    max_depth):\n",
    "    \n",
    "    \n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. So we make them integer\n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "\n",
    "    param = {\n",
    "        'num_leaves': num_leaves,\n",
    "        'min_data_in_leaf': min_data_in_leaf,\n",
    "        'learning_rate': learning_rate,\n",
    "        'max_depth': max_depth,\n",
    "        'lambda_l1': lambda_l1,\n",
    "        'save_binary': True, \n",
    "        'seed': 123,\n",
    "        'bagging_seed': 123,\n",
    "        'drop_seed': 123,\n",
    "        'data_random_seed': 123,\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbose': 1,\n",
    "        'metric': 'auc',\n",
    "        'is_unbalance': True,   \n",
    "\n",
    "    }    \n",
    "    \n",
    "    \n",
    "    xg_train = lgb.Dataset(train.iloc[bayesian_tr_index][feats].values,\n",
    "                           label=y.iloc[bayesian_tr_index].values,\n",
    "                           \n",
    "                           free_raw_data = False\n",
    "                           )\n",
    "    xg_valid = lgb.Dataset(train.iloc[bayesian_val_index][feats].values,\n",
    "                           label=y.iloc[bayesian_val_index].values,\n",
    "                           \n",
    "                           free_raw_data = False\n",
    "                           )   \n",
    "\n",
    "    num_round = 5000\n",
    "    clf = lgb.train(param, xg_train, num_round, valid_sets = [xg_valid], verbose_eval=250, early_stopping_rounds = 50)\n",
    "    \n",
    "    predictions = clf.predict(train.iloc[bayesian_val_index][feats].values, num_iteration=clf.best_iteration)   \n",
    "    \n",
    "    score = roc_auc_score(y.iloc[bayesian_val_index].values, predictions)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bay_param={\n",
    "    'num_leaves': (30,70), \n",
    "    'min_data_in_leaf': (10,70),  \n",
    "    'learning_rate': (0.01, 0.3),\n",
    "    'feature_fraction': (0.05, 0.5),\n",
    "    'lambda_l1': (0, 5.0), \n",
    "    'max_depth':(3,15)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_BO = BayesianOptimization(LGB_bayesian, bay_param, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_points=3\n",
    "n_iter=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | featur... | lambda_l1 | learni... | max_depth | min_da... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[250]\tvalid_0's auc: 0.770767\n",
      "Early stopping, best iteration is:\n",
      "[442]\tvalid_0's auc: 0.772888\n",
      "|  1        |  0.7729   |  0.3634   |  1.431    |  0.07579  |  9.616    |  53.17    |  46.92    |\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[250]\tvalid_0's auc: 0.770955\n",
      "Early stopping, best iteration is:\n",
      "[222]\tvalid_0's auc: 0.771078\n",
      "|  2        |  0.7711   |  0.4913   |  3.424    |  0.1495   |  7.705    |  30.59    |  59.16    |\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[250]\tvalid_0's auc: 0.771209\n",
      "Early stopping, best iteration is:\n",
      "[249]\tvalid_0's auc: 0.771223\n",
      "|  3        |  0.7712   |  0.2474   |  0.2984   |  0.1254   |  11.86    |  20.95    |  37.02    |\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[250]\tvalid_0's auc: 0.77346\n",
      "[500]\tvalid_0's auc: 0.77741\n",
      "[750]\tvalid_0's auc: 0.778283\n",
      "[1000]\tvalid_0's auc: 0.778751\n",
      "Early stopping, best iteration is:\n",
      "[1002]\tvalid_0's auc: 0.778763\n",
      "|  4        |  0.7788   |  0.4437   |  4.864    |  0.2129   |  3.196    |  69.76    |  30.27    |\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[250]\tvalid_0's auc: 0.757814\n",
      "[500]\tvalid_0's auc: 0.766166\n",
      "[750]\tvalid_0's auc: 0.769474\n",
      "[1000]\tvalid_0's auc: 0.771367\n",
      "[1250]\tvalid_0's auc: 0.772328\n",
      "[1500]\tvalid_0's auc: 0.773072\n",
      "[1750]\tvalid_0's auc: 0.773903\n",
      "[2000]\tvalid_0's auc: 0.774304\n",
      "Early stopping, best iteration is:\n",
      "[2083]\tvalid_0's auc: 0.774534\n",
      "|  5        |  0.7745   |  0.3112   |  4.978    |  0.02082  |  13.83    |  69.37    |  30.54    |\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[250]\tvalid_0's auc: 0.764226\n",
      "[500]\tvalid_0's auc: 0.769477\n",
      "[750]\tvalid_0's auc: 0.772356\n",
      "[1000]\tvalid_0's auc: 0.774568\n",
      "[1250]\tvalid_0's auc: 0.776094\n",
      "[1500]\tvalid_0's auc: 0.777067\n",
      "[1750]\tvalid_0's auc: 0.777715\n",
      "[2000]\tvalid_0's auc: 0.778218\n",
      "[2250]\tvalid_0's auc: 0.778422\n",
      "[2500]\tvalid_0's auc: 0.778793\n",
      "Early stopping, best iteration is:\n",
      "[2685]\tvalid_0's auc: 0.77904\n",
      "|  6        |  0.779    |  0.4441   |  0.01078  |  0.06815  |  3.467    |  68.93    |  31.11    |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print('-' * 150)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points,n_iter=n_iter,alpha=1e-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_fraction': 0.44409372851515394,\n",
       " 'lambda_l1': 0.010784561545872373,\n",
       " 'learning_rate': 0.06815113734587146,\n",
       " 'max_depth': 3.4673240905177125,\n",
       " 'min_data_in_leaf': 68.92857798548327,\n",
       " 'num_leaves': 31.109834110784448}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB_BO.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param = {'num_leaves': 60,\n",
    "#          'min_data_in_leaf': 60, \n",
    "#          'objective':'binary',\n",
    "#          'max_depth': -1,\n",
    "#          'learning_rate': 0.1,\n",
    "#          \"boosting\": \"gbdt\",\n",
    "#          \"feature_fraction\": 0.8,\n",
    "#          \"bagging_freq\": 1,\n",
    "#          \"bagging_fraction\": 0.8 ,\n",
    "#          \"bagging_seed\": 11,\n",
    "#          \"metric\": 'auc',\n",
    "#          \"lambda_l1\": 0.1,\n",
    "#          \"random_state\": 133,\n",
    "#          \"verbosity\": -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params after bayesian optimisation:\n",
    "\n",
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 69, \n",
    "         'objective':'binary',\n",
    "         'max_depth': 4,\n",
    "         'learning_rate': 0.06,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.33,\n",
    "         \"metric\": 'auc',\n",
    "         \"lambda_l1\": 0.01,\n",
    "         \"random_state\": 133,\n",
    "         \"verbosity\": -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold nÂ°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\Miniconda3\\lib\\site-packages\\lightgbm\\basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\deepa\\Miniconda3\\lib\\site-packages\\lightgbm\\basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.811879\tvalid_1's auc: 0.777955\n",
      "[200]\ttraining's auc: 0.842821\tvalid_1's auc: 0.788593\n",
      "[300]\ttraining's auc: 0.858847\tvalid_1's auc: 0.791891\n",
      "[400]\ttraining's auc: 0.870213\tvalid_1's auc: 0.793363\n",
      "[500]\ttraining's auc: 0.876864\tvalid_1's auc: 0.794068\n",
      "[600]\ttraining's auc: 0.881991\tvalid_1's auc: 0.794513\n",
      "[700]\ttraining's auc: 0.88593\tvalid_1's auc: 0.79476\n",
      "[800]\ttraining's auc: 0.890052\tvalid_1's auc: 0.794652\n",
      "[900]\ttraining's auc: 0.893563\tvalid_1's auc: 0.794376\n",
      "Early stopping, best iteration is:\n",
      "[734]\ttraining's auc: 0.887034\tvalid_1's auc: 0.794813\n",
      "Fold 1: Most important features are:\n",
      "\n",
      "nom_9_LE-->67420.97451972961\n",
      "nom_6_FE-->73209.61964058876\n",
      "nom_8_LE-->88927.89646756649\n",
      "nom_7_LE-->93389.90722155571\n",
      "ord_5_FE-->98690.93132388592\n",
      "Fold  1 AUC : 0.794813\n",
      "fold nÂ°2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\Miniconda3\\lib\\site-packages\\lightgbm\\basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\deepa\\Miniconda3\\lib\\site-packages\\lightgbm\\basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.811679\tvalid_1's auc: 0.776536\n",
      "[200]\ttraining's auc: 0.841886\tvalid_1's auc: 0.78824\n",
      "[300]\ttraining's auc: 0.857558\tvalid_1's auc: 0.792274\n",
      "[400]\ttraining's auc: 0.869453\tvalid_1's auc: 0.794206\n",
      "[500]\ttraining's auc: 0.876101\tvalid_1's auc: 0.795125\n",
      "[600]\ttraining's auc: 0.881031\tvalid_1's auc: 0.795686\n",
      "[700]\ttraining's auc: 0.88518\tvalid_1's auc: 0.795913\n",
      "[800]\ttraining's auc: 0.889347\tvalid_1's auc: 0.795782\n",
      "[900]\ttraining's auc: 0.892984\tvalid_1's auc: 0.795724\n",
      "Early stopping, best iteration is:\n",
      "[758]\ttraining's auc: 0.887613\tvalid_1's auc: 0.795956\n",
      "Fold 2: Most important features are:\n",
      "\n",
      "nom_5_FE-->67740.34781748056\n",
      "nom_6_FE-->73109.19807302952\n",
      "nom_8_LE-->86625.97900009155\n",
      "nom_7_LE-->97201.71965074539\n",
      "ord_5_FE-->99465.74937680364\n",
      "Fold  2 AUC : 0.795956\n",
      "fold nÂ°3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\Miniconda3\\lib\\site-packages\\lightgbm\\basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\deepa\\Miniconda3\\lib\\site-packages\\lightgbm\\basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.811692\tvalid_1's auc: 0.776925\n",
      "[200]\ttraining's auc: 0.841777\tvalid_1's auc: 0.788139\n",
      "[300]\ttraining's auc: 0.857718\tvalid_1's auc: 0.791788\n",
      "[400]\ttraining's auc: 0.868986\tvalid_1's auc: 0.793557\n",
      "[500]\ttraining's auc: 0.875916\tvalid_1's auc: 0.794369\n",
      "[600]\ttraining's auc: 0.880902\tvalid_1's auc: 0.794787\n",
      "[700]\ttraining's auc: 0.884956\tvalid_1's auc: 0.794968\n",
      "[800]\ttraining's auc: 0.88915\tvalid_1's auc: 0.79474\n",
      "Early stopping, best iteration is:\n",
      "[674]\ttraining's auc: 0.883974\tvalid_1's auc: 0.795057\n",
      "Fold 3: Most important features are:\n",
      "\n",
      "nom_5_FE-->64530.66731393337\n",
      "nom_6_FE-->70967.87460744381\n",
      "nom_8_LE-->86735.7122707367\n",
      "nom_7_LE-->89998.23136329651\n",
      "ord_5_FE-->98152.36149513721\n",
      "Fold  3 AUC : 0.795057\n",
      "fold nÂ°4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\Miniconda3\\lib\\site-packages\\lightgbm\\basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\deepa\\Miniconda3\\lib\\site-packages\\lightgbm\\basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.81238\tvalid_1's auc: 0.77463\n",
      "[200]\ttraining's auc: 0.842337\tvalid_1's auc: 0.78555\n",
      "[300]\ttraining's auc: 0.858409\tvalid_1's auc: 0.788866\n",
      "[400]\ttraining's auc: 0.870006\tvalid_1's auc: 0.790355\n",
      "[500]\ttraining's auc: 0.876864\tvalid_1's auc: 0.791324\n",
      "[600]\ttraining's auc: 0.882023\tvalid_1's auc: 0.791562\n",
      "[700]\ttraining's auc: 0.886209\tvalid_1's auc: 0.791634\n",
      "[800]\ttraining's auc: 0.89035\tvalid_1's auc: 0.791664\n",
      "[900]\ttraining's auc: 0.893884\tvalid_1's auc: 0.791479\n",
      "Early stopping, best iteration is:\n",
      "[737]\ttraining's auc: 0.887395\tvalid_1's auc: 0.791805\n",
      "Fold 4: Most important features are:\n",
      "\n",
      "nom_9_LE-->67800.31713676453\n",
      "nom_6_FE-->74421.83401936293\n",
      "nom_8_LE-->87794.76416492462\n",
      "nom_7_LE-->94528.62718009949\n",
      "ord_5_FE-->99506.84189277887\n",
      "Fold  4 AUC : 0.791805\n",
      "fold nÂ°5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\Miniconda3\\lib\\site-packages\\lightgbm\\basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\deepa\\Miniconda3\\lib\\site-packages\\lightgbm\\basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.812541\tvalid_1's auc: 0.776299\n",
      "[200]\ttraining's auc: 0.842658\tvalid_1's auc: 0.787245\n",
      "[300]\ttraining's auc: 0.858716\tvalid_1's auc: 0.790882\n",
      "[400]\ttraining's auc: 0.870606\tvalid_1's auc: 0.792234\n",
      "[500]\ttraining's auc: 0.877143\tvalid_1's auc: 0.793063\n",
      "[600]\ttraining's auc: 0.882093\tvalid_1's auc: 0.79337\n",
      "[700]\ttraining's auc: 0.886037\tvalid_1's auc: 0.793492\n",
      "[800]\ttraining's auc: 0.890215\tvalid_1's auc: 0.793477\n",
      "[900]\ttraining's auc: 0.893718\tvalid_1's auc: 0.793362\n",
      "Early stopping, best iteration is:\n",
      "[752]\ttraining's auc: 0.888206\tvalid_1's auc: 0.793617\n",
      "Fold 5: Most important features are:\n",
      "\n",
      "nom_9_LE-->70548.29574012756\n",
      "nom_6_FE-->73361.55004185438\n",
      "nom_8_LE-->88230.54189872742\n",
      "nom_7_LE-->95761.65492653847\n",
      "ord_5_FE-->100280.53248739243\n",
      "Fold  5 AUC : 0.793617\n",
      "Full auc score 0.794241\n"
     ]
    }
   ],
   "source": [
    "for n_folds,(train_idx,valid_idx) in enumerate(folds.split(train.values,y.values)):\n",
    "    print(\"fold nÂ°{}\".format(n_folds+1))\n",
    "    trn_data = lgb.Dataset(train.iloc[train_idx][feats],\n",
    "                           label=y.iloc[train_idx],\n",
    "                           categorical_feature=categorical_features\n",
    "                          )\n",
    "    val_data = lgb.Dataset(train.iloc[valid_idx][feats],\n",
    "                           label=y.iloc[valid_idx],categorical_feature=categorical_features\n",
    "                          )\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds = 200)\n",
    "    \n",
    "    #clf.fit(train_x,train_y,eval_set=[(train_x,train_y),(valid_x,valid_y)],verbose=500,eval_metric=\"auc\",early_stopping_rounds=100)\n",
    "    \n",
    "    oof_preds[valid_idx]=clf.predict(train.iloc[valid_idx][feats],num_iteration=clf.best_iteration)\n",
    "    sub_preds+=clf.predict(test[feats],num_iteration=clf.best_iteration)/folds.n_splits\n",
    "    \n",
    "    fold_importance_df=pd.DataFrame()\n",
    "    fold_importance_df['features']=feats\n",
    "    fold_importance_df['importance']=clf.feature_importance(importance_type='gain')\n",
    "    fold_importance_df['folds']=n_folds+1\n",
    "    print(f'Fold {n_folds+1}: Most important features are:\\n')\n",
    "    for i in np.argsort(fold_importance_df['importance'])[-5:]:\n",
    "        print(f'{fold_importance_df.iloc[i,0]}-->{fold_importance_df.iloc[i,1]}')\n",
    "    \n",
    "    feature_importance_df=pd.concat([feature_importance_df,fold_importance_df],axis=0)\n",
    "    \n",
    "    print('Fold %2d AUC : %.6f' % (n_folds + 1, roc_auc_score(y.iloc[valid_idx], oof_preds[valid_idx])))\n",
    "    del clf\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "\n",
    "print('Full auc score %.6f' % (roc_auc_score(y,oof_preds)))\n",
    "\n",
    "test['target']=sub_preds\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target']=sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.293341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300001</td>\n",
       "      <td>0.544078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300002</td>\n",
       "      <td>0.210609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300003</td>\n",
       "      <td>0.309833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300004</td>\n",
       "      <td>0.705689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    target\n",
       "0  300000  0.293341\n",
       "1  300001  0.544078\n",
       "2  300002  0.210609\n",
       "3  300003  0.309833\n",
       "4  300004  0.705689"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"sample_submission_01.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
